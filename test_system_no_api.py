#!/usr/bin/env python3
"""
ç³»ç»Ÿæµ‹è¯•è„šæœ¬ - ä¸éœ€è¦çœŸå®APIå¯†é’¥
æµ‹è¯•å°ç‹å­è®°å¿†æ„æ¶ç³»ç»Ÿçš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from core import LittlePrinceAgent


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹ç³»ç»Ÿæµ‹è¯•...")
    
    try:
        # 1. æµ‹è¯•é…ç½®åŠ è½½
        print("1. æµ‹è¯•é…ç½®åŠ è½½...")
        config = Config()
        print(f"   âœ… é…ç½®åŠ è½½æˆåŠŸ: {config.LLM_PROVIDER} - {config.LLM_MODEL}")
        
        # 2. æµ‹è¯•Agentåˆå§‹åŒ–
        print("2. æµ‹è¯•Agentåˆå§‹åŒ–...")
        agent = LittlePrinceAgent(config)
        print("   âœ… Agentåˆå§‹åŒ–æˆåŠŸ")
        
        # 3. æµ‹è¯•è®°å¿†åŠŸèƒ½ï¼ˆä¸è°ƒç”¨LLMï¼‰
        print("3. æµ‹è¯•è®°å¿†åŠŸèƒ½...")
        
        # æ¨¡æ‹Ÿæ·»åŠ å¯¹è¯åˆ°è®°å¿†
        agent.memory_room.add_conversation("æˆ‘å«å°æ˜ï¼Œæˆ‘å–œæ¬¢çœ‹æ˜Ÿæ˜Ÿ", "ä½ å¥½å°æ˜ï¼æˆ‘ä¹Ÿå–œæ¬¢çœ‹æ˜Ÿæ˜Ÿå‘¢ã€‚")
        agent.memory_room.add_conversation("æˆ‘ä»Šå¹´25å²ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜", "å“‡ï¼Œç¨‹åºå‘˜ï¼ä½ ä¸€å®šå¾ˆèªæ˜ã€‚")
        
        stats = agent.get_memory_stats()
        print(f"   âœ… è®°å¿†ç»Ÿè®¡: çŸ­æœŸ{stats['short_term_count']}è½®, é•¿æœŸäº‹å®{stats['long_term_factual_count']}é¡¹")
        
        # 4. æµ‹è¯•è®°å¿†æ›´æ–°æœºåˆ¶
        print("4. æµ‹è¯•è®°å¿†æ›´æ–°æœºåˆ¶...")
        agent.memory_update_mechanism.current_round = 10  # æ¨¡æ‹Ÿç¬¬10è½®
        if agent.memory_update_mechanism.should_trigger_update():
            print("   âœ… è®°å¿†æ›´æ–°è§¦å‘æ¡ä»¶æ­£ç¡®")
        else:
            print("   âŒ è®°å¿†æ›´æ–°è§¦å‘æ¡ä»¶é”™è¯¯")
        
        # 5. æµ‹è¯•è®°å¿†äº¤äº’
        print("5. æµ‹è¯•è®°å¿†äº¤äº’...")
        context = agent.memory_interaction.get_context(agent.memory_room)
        print(f"   âœ… ä¸Šä¸‹æ–‡æ„å»ºæˆåŠŸï¼Œé•¿åº¦: {len(context)}")
        
        print("\nğŸ‰ æ‰€æœ‰åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("æ³¨æ„ï¼šç”±äºæ²¡æœ‰çœŸå®çš„APIå¯†é’¥ï¼ŒLLMè°ƒç”¨åŠŸèƒ½æœªæµ‹è¯•")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_model_switch():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½...")
    
    try:
        config = Config()
        agent = LittlePrinceAgent(config)
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å‹
        model_config = config.get_model_config()
        print(f"å½“å‰æ¨¡å‹: {model_config['provider']} - {model_config['model']}")
        
        # æµ‹è¯•æ¨¡å‹åˆ‡æ¢ï¼ˆä¸å®é™…è°ƒç”¨APIï¼‰
        print("æµ‹è¯•æ¨¡å‹åˆ‡æ¢é€»è¾‘...")
        agent.switch_model("deepseek", "deepseek-chat", "test_key")
        print("   âœ… æ¨¡å‹åˆ‡æ¢é€»è¾‘æ­£å¸¸")
        
        print("âœ… æ¨¡å‹åˆ‡æ¢æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # è®¾ç½®æµ‹è¯•APIå¯†é’¥
    os.environ["LLM_API_KEY"] = "test_key_for_testing"
    
    # è¿è¡Œæµ‹è¯•
    test_basic_functionality()
    test_model_switch()
    
    print("\nğŸ“ æµ‹è¯•æ€»ç»“:")
    print("- âœ… é…ç½®ç³»ç»Ÿæ­£å¸¸å·¥ä½œ")
    print("- âœ… Agentåˆå§‹åŒ–æˆåŠŸ")
    print("- âœ… è®°å¿†ç³»ç»ŸåŠŸèƒ½æ­£å¸¸")
    print("- âœ… æ¨¡å‹åˆ‡æ¢é€»è¾‘æ­£ç¡®")
    print("- âš ï¸  LLMè°ƒç”¨åŠŸèƒ½éœ€è¦çœŸå®APIå¯†é’¥æµ‹è¯•")
