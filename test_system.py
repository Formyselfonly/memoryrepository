#!/usr/bin/env python3
"""
ç³»ç»Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•å°ç‹å­è®°å¿†æ„æ¶ç³»ç»Ÿçš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from core import LittlePrinceAgent


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹ç³»ç»Ÿæµ‹è¯•...")
    
    try:
        # 1. æµ‹è¯•é…ç½®åŠ è½½
        print("1. æµ‹è¯•é…ç½®åŠ è½½...")
        config = Config()
        print(f"   âœ… é…ç½®åŠ è½½æˆåŠŸ: {config.LLM_PROVIDER} - {config.LLM_MODEL}")
        
        # 2. æµ‹è¯•Agentåˆå§‹åŒ–
        print("2. æµ‹è¯•Agentåˆå§‹åŒ–...")
        agent = LittlePrinceAgent(config)
        print("   âœ… Agentåˆå§‹åŒ–æˆåŠŸ")
        
        # 3. æµ‹è¯•åŸºæœ¬å¯¹è¯
        print("3. æµ‹è¯•åŸºæœ¬å¯¹è¯...")
        response = agent.chat("ä½ å¥½ï¼Œæˆ‘æ˜¯æµ‹è¯•ç”¨æˆ·")
        print(f"   âœ… å¯¹è¯æˆåŠŸ: {response[:50]}...")
        
        # 4. æµ‹è¯•è®°å¿†åŠŸèƒ½
        print("4. æµ‹è¯•è®°å¿†åŠŸèƒ½...")
        agent.chat("æˆ‘å«å°æ˜ï¼Œæˆ‘å–œæ¬¢çœ‹æ˜Ÿæ˜Ÿ")
        agent.chat("æˆ‘ä»Šå¹´25å²ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜")
        
        stats = agent.get_memory_stats()
        print(f"   âœ… è®°å¿†ç»Ÿè®¡: çŸ­æœŸ{stats['short_term_count']}è½®, é•¿æœŸäº‹å®{stats['long_term_factual_count']}é¡¹")
        
        # 5. æµ‹è¯•è®°å¿†åº”ç”¨
        print("5. æµ‹è¯•è®°å¿†åº”ç”¨...")
        response = agent.chat("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")
        print(f"   âœ… è®°å¿†åº”ç”¨: {response[:50]}...")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_model_switch():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½...")
    
    try:
        config = Config()
        agent = LittlePrinceAgent(config)
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å‹
        model_config = config.get_model_config()
        print(f"å½“å‰æ¨¡å‹: {model_config['provider']} - {model_config['model']}")
        
        # æµ‹è¯•å¯¹è¯
        response = agent.chat("æµ‹è¯•æ¨¡å‹åˆ‡æ¢å‰çš„å¯¹è¯")
        print(f"åˆ‡æ¢å‰: {response[:30]}...")
        
        # åˆ‡æ¢æ¨¡å‹ï¼ˆå¦‚æœé…ç½®äº†ä¸åŒçš„APIå¯†é’¥ï¼‰
        if os.getenv("DEEPSEEK_API_KEY"):
            print("åˆ‡æ¢åˆ°DeepSeekæ¨¡å‹...")
            agent.switch_model("deepseek", "deepseek-chat", os.getenv("DEEPSEEK_API_KEY"))
            
            response = agent.chat("æµ‹è¯•æ¨¡å‹åˆ‡æ¢åçš„å¯¹è¯")
            print(f"åˆ‡æ¢å: {response[:30]}...")
        
        print("âœ… æ¨¡å‹åˆ‡æ¢æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("LLM_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½®LLM_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·å¤åˆ¶env.exampleä¸º.envå¹¶è®¾ç½®æ‚¨çš„APIå¯†é’¥")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    test_basic_functionality()
    test_model_switch()
